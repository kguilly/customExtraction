{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from herbie import Herbie\n",
    "from datetime import datetime, timedelta\n",
    "import pygrib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "parameters = np.linspace(1, 150, num=150, dtype=int)\n",
    "date = \"20230201\"\n",
    "dt = date + \" 10:00\"\n",
    "save_dir = '/Users/kkjesus/data/'\n",
    "pred_hours = 1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "H2 = Herbie(\n",
    "    dt,\n",
    "    model=\"hrrr\",\n",
    "    product=\"nat\",\n",
    "    save_dir=save_dir,\n",
    "    fxx=pred_hours,\n",
    "    verbose=True,\n",
    "    overwrite=False\n",
    ").download(\":APCP:surface:\")\n",
    "    # .download()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "grib_path = '/Users/kkjesus/data/hrrr/20230201/subset_85e4fa12__hrrr.t10z.wrfnatf01.grib2'\n",
    "grib = pygrib.open(grib_path)\n",
    "print(grib)\n",
    "print(\"grib\")\n",
    "# H2.tell_me_everything()\n",
    "for g in grib:\n",
    "    print(g)\n",
    "    # lats, lons = g.latlons()\n",
    "    # values = g.values\n",
    "    # print(lats.min(), lats.max(), lons.min(), lons.max())\n",
    "    # print(values.shape, values.min(), values.max())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: 1 Name: Total Precipitation  Units: kg m**-2  Level: 0 (surface)\n",
      "30.23591780027958\n",
      "-92.03036502874882\n",
      "227   1076\n",
      "\n",
      "0.001\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (1059, 1799)\n",
      "Not that many messages\n"
     ]
    }
   ],
   "source": [
    "for p in parameters:\n",
    "    try:\n",
    "        grib_msgs = grib[int(p)]\n",
    "    except OSError:\n",
    "        print(\"Not that many messages\")\n",
    "        break\n",
    "    print(\"Layer: %s Name: %s  Units: %s  Level: %s (%s)\" % (\n",
    "    p, grib_msgs.name, grib_msgs.units, grib_msgs.level, grib_msgs.typeOfLevel))\n",
    "    lat_st_mid = 30.2241\n",
    "    lon_st_mid = -92.0198\n",
    "    data = grib_msgs.values\n",
    "    lt, ln = grib_msgs.latlons()\n",
    "    st_lt_m = np.full_like(lt, lat_st_mid)\n",
    "    st_ln_m = np.full_like(ln, lon_st_mid)\n",
    "    dis_mat = (lt - st_lt_m) ** 2 + (ln - st_ln_m) ** 2\n",
    "    p_lt, p_ln = np.unravel_index(dis_mat.argmin(), dis_mat.shape)\n",
    "    value = data[p_lt, p_ln]\n",
    "    print(lt[p_lt][p_ln])\n",
    "    print(ln[p_lt,p_ln])\n",
    "    print(p_lt, \" \", p_ln)\n",
    "    print()\n",
    "    print(value)\n",
    "    print(data, data.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# df = {\n",
    "#     \"car\" : [1, 2, 3],\n",
    "#     \"boat\": [4, 5, 6],\n",
    "# }\n",
    "df = pd.DataFrame({\n",
    "    \"car\" : [1, 2, 3],\n",
    "    \"boat\": [4, 5, 6],\n",
    "    \"george\": [10,11,12]\n",
    "})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   car  boat  george\n",
      "0    1     4      10\n",
      "1    2     5      11\n",
      "2    3     6      12\n",
      "3   11    44      77\n",
      "4   22    55      88\n",
      "5   33    66      99\n"
     ]
    }
   ],
   "source": [
    "# df = pd.concat([df, pd.Series([7,8,9])], ignore_index=True, axis=0, join='outer')\n",
    "df2 = pd.DataFrame({\n",
    "    \"car\" : [11, 22, 33],\n",
    "    \"boat\" : [44,55,66],\n",
    "    \"george\" : [77,88,99]\n",
    "})\n",
    "df = df.merge(df2, how='outer')\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 33\n"
     ]
    }
   ],
   "source": [
    "print(df['car'][0], df['car'][len(df)-1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kaleb/Desktop/WRFextract_2-3/Daily_Monthly/\n"
     ]
    }
   ],
   "source": [
    "dir = \"/home/kaleb/Desktop/WRFextract_2-3/Hourly/\"\n",
    "filepathsep = dir.split('/')\n",
    "hourly_file_path = ''\n",
    "for i in range(len(filepathsep) - 1):\n",
    "    if filepathsep[i].rfind(\"Hourly\") != -1:\n",
    "        break\n",
    "    hourly_file_path += filepathsep[i] + '/'\n",
    "hourly_file_path += \"Daily_Monthly/\"\n",
    "print(hourly_file_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/kaleb/Desktop/WRFextract_2-3/Daily_Monthly/'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m df_states \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m fips_folder \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlistdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhourly_file_path\u001B[49m\u001B[43m)\u001B[49m):\n\u001B[1;32m      3\u001B[0m     fips_dir \u001B[38;5;241m=\u001B[39m hourly_file_path \u001B[38;5;241m+\u001B[39m fips_folder \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# print(fips_dir)\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/kaleb/Desktop/WRFextract_2-3/Daily_Monthly/'"
     ]
    }
   ],
   "source": [
    "df_states = {}\n",
    "for fips_folder in sorted(os.listdir(hourly_file_path)):\n",
    "    fips_dir = hourly_file_path + fips_folder + '/'\n",
    "    # print(fips_dir)\n",
    "    for monthly_file in sorted(os.listdir(fips_dir)):\n",
    "        # print(monthly_file)\n",
    "        full_path = fips_dir + monthly_file\n",
    "        state_fips = monthly_file[5:7]\n",
    "        state_abbrev = monthly_file[11:13]\n",
    "        year = monthly_file[14:18]\n",
    "        month = monthly_file[18:20]\n",
    "        col_name = state_fips + '_' + year + '_' + month\n",
    "        if not col_name in df_states:\n",
    "            df_states[col_name] = []\n",
    "        df_states[col_name].append(full_path)\n",
    "        # try:\n",
    "        #     df_states[col_name].loc[0] = full_path\n",
    "        # except:\n",
    "        #     df_states.index = df_states.index + 1\n",
    "        #     df_states[col_name].loc[0] = full_path\n",
    "        # prints empty df\n",
    "        # df_states = df_states.append({col_name:full_path}, ignore_index=True)\n",
    "        # df_states = df.merge()\n",
    "print(df_states)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17_2023_01\n",
      "/home/kaleb/Desktop/WRFextract_2-3/Daily_Monthly/17091/HRRR_17091_IL_202301.csv\n",
      "/home/kaleb/Desktop/WRFextract_2-3/Daily_Monthly/17155/HRRR_17155_IL_202301.csv\n",
      "['HRRR', '17091', 'IL', '202301.csv']\n"
     ]
    }
   ],
   "source": [
    "for col in df_states:\n",
    "    print(col)\n",
    "    for dir in df_states[col]:\n",
    "        print(dir)\n",
    "    in_file_path_sep = df_states[col][0].split('/')\n",
    "    needed_info_sep = in_file_path_sep[-1].split('_')\n",
    "    print(needed_info_sep)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 0., 0., 0., 0., 0.])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(len(df))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
